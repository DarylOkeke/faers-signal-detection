#!/usr/bin/env python3
"""
Create Trimmed Decision Tables for MINOXIDIL Cardiac Endpoints

This script creates focused decision tables from the full signal detection summary,
concentrating on cardiac endpoints for MINOXIDIL cohorts with clear interpretations.

Author: FAERS Signal Detection Team
Date: August 2025
"""

import argparse
import pandas as pd
import numpy as np
import os
import sys
from pathlib import Path

# Target cardiac endpoints in specified order
PT_ORDER = ['CARDIAC TAMPONADE', 'PERICARDIAL EFFUSION', 'PERICARDITIS', 'PLEURAL EFFUSION']

def load_summary_data(input_path):
    """
    Load the full summary CSV generated by compute_summary.py.
    
    Args:
        input_path: Path to summary CSV file
        
    Returns:
        pandas.DataFrame: Full summary data
    """
    if not os.path.exists(input_path):
        raise FileNotFoundError(f"Summary file not found: {input_path}")
    
    df = pd.read_csv(input_path)
    print(f"✓ Loaded {len(df):,} rows from {input_path}")
    
    return df

def filter_to_targets(df, include_topical=False):
    """
    Filter summary data to target cohorts and cardiac endpoints.
    
    Args:
        df: Full summary DataFrame
        include_topical: Whether to include MINOXIDIL_TOPICAL
        
    Returns:
        pandas.DataFrame: Filtered data
    """
    # Define target cohorts
    target_cohorts = ['MINOXIDIL_SYSTEMIC']
    if include_topical:
        target_cohorts.append('MINOXIDIL_TOPICAL')
    
    # Filter to target cohorts and cardiac endpoints
    filtered_df = df[
        (df['cohort'].isin(target_cohorts)) & 
        (df['reaction_pt'].isin(PT_ORDER))
    ].copy()
    
    print(f"✓ Filtered to {len(filtered_df)} rows for target cohorts and cardiac endpoints")
    
    return filtered_df

def ensure_complete_matrix(df, include_topical=False):
    """
    Ensure all cohort-PT combinations exist, filling missing with zeros.
    
    Args:
        df: Filtered DataFrame
        include_topical: Whether topical cohort should be included
        
    Returns:
        pandas.DataFrame: Complete matrix with all combinations
    """
    # Define expected cohorts
    cohorts = ['MINOXIDIL_SYSTEMIC']
    if include_topical:
        cohorts.append('MINOXIDIL_TOPICAL')
    
    # Create complete index of all combinations
    complete_index = pd.MultiIndex.from_product(
        [cohorts, PT_ORDER], 
        names=['cohort', 'reaction_pt']
    )
    
    # Set index for merging
    df_indexed = df.set_index(['cohort', 'reaction_pt'])
    
    # Reindex to ensure all combinations exist
    complete_df = df_indexed.reindex(complete_index)
    
    # Fill missing values for rows that don't exist
    fill_values = {
        'a': 0, 'b': 0, 'c': 0, 'd': 0, 'N': 0,
        'PRR': 0.0, 'PRR_LCL': 0.0, 'PRR_UCL': 0.0,
        'ROR': 0.0, 'ROR_LCL': 0.0, 'ROR_UCL': 0.0,
        'chi2': 0.0, 'flagged': False
    }
    
    for col, value in fill_values.items():
        if col in complete_df.columns:
            complete_df[col] = complete_df[col].fillna(value)
    
    # Reset index
    complete_df = complete_df.reset_index()
    
    print(f"✓ Ensured complete matrix: {len(complete_df)} rows")
    
    return complete_df

def add_decision_columns(df):
    """
    Add decision and interpretation columns based on flagging results.
    
    Args:
        df: DataFrame with flagged column
        
    Returns:
        pandas.DataFrame: DataFrame with added decision columns
    """
    # Add decision column
    df['decision'] = df['flagged'].apply(
        lambda x: 'Reject H0 (signal)' if x else 'Fail to reject H0'
    )
    
    # Add interpretation column
    interpretations = []
    for _, row in df.iterrows():
        cohort = row['cohort']
        reaction_pt = row['reaction_pt']
        prr = row['PRR']
        prr_lcl = row['PRR_LCL']
        prr_ucl = row['PRR_UCL']
        n = int(row['N'])
        
        if row['flagged']:
            interpretation = (
                f"{cohort}: Disproportionate reporting for {reaction_pt} "
                f"(PRR={prr:.1f}, 95% CI {prr_lcl:.1f}-{prr_ucl:.1f}, N={n})"
            )
        else:
            interpretation = (
                f"{cohort}: No disproportionate reporting for {reaction_pt} "
                f"(PRR={prr:.1f}, N={n})"
            )
        
        interpretations.append(interpretation)
    
    df['interpretation'] = interpretations
    
    return df

def sort_results(df):
    """
    Sort results by cohort and PT in specified order.
    
    Args:
        df: DataFrame to sort
        
    Returns:
        pandas.DataFrame: Sorted DataFrame
    """
    # Create categorical for proper PT ordering
    df['reaction_pt_cat'] = pd.Categorical(
        df['reaction_pt'], 
        categories=PT_ORDER, 
        ordered=True
    )
    
    # Sort by cohort (ascending) then PT in specified order
    sorted_df = df.sort_values(['cohort', 'reaction_pt_cat'])
    
    # Drop the categorical helper column
    sorted_df = sorted_df.drop(columns=['reaction_pt_cat'])
    
    return sorted_df

def trim_columns(df):
    """
    Select and reorder columns for final output.
    
    Args:
        df: DataFrame with all columns
        
    Returns:
        pandas.DataFrame: Trimmed DataFrame
    """
    # Select desired columns in specified order
    output_columns = [
        'cohort', 'reaction_pt', 'N', 'PRR', 'PRR_LCL', 'PRR_UCL', 
        'chi2', 'flagged', 'decision', 'interpretation'
    ]
    
    return df[output_columns]

def save_csv(df, output_path):
    """
    Save DataFrame to CSV file.
    
    Args:
        df: DataFrame to save
        output_path: Output CSV file path
    """
    # Create output directory if needed
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Round numeric columns for cleaner output
    numeric_cols = ['PRR', 'PRR_LCL', 'PRR_UCL', 'chi2']
    df_rounded = df.copy()
    for col in numeric_cols:
        if col in df_rounded.columns:
            df_rounded[col] = df_rounded[col].round(3)
    
    # Save to CSV
    df_rounded.to_csv(output_path, index=False)
    print(f"✓ Saved trimmed CSV to: {output_path}")

def save_markdown(df, output_path):
    """
    Save DataFrame to Markdown table file.
    
    Args:
        df: DataFrame to save
        output_path: Output Markdown file path
    """
    # Create output directory if needed
    output_dir = Path(output_path).parent
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # Round numeric columns
    numeric_cols = ['PRR', 'PRR_LCL', 'PRR_UCL', 'chi2']
    df_rounded = df.copy()
    for col in numeric_cols:
        if col in df_rounded.columns:
            df_rounded[col] = df_rounded[col].round(3)
    
    # Create markdown manually (without requiring tabulate)
    markdown_content = "# MINOXIDIL Cardiac Endpoints Signal Detection Results\n\n"
    
    # Create table header
    headers = df_rounded.columns.tolist()
    header_line = "| " + " | ".join(headers) + " |\n"
    separator_line = "|" + "|".join([" --- " for _ in headers]) + "|\n"
    
    markdown_content += header_line
    markdown_content += separator_line
    
    # Add data rows
    for _, row in df_rounded.iterrows():
        row_values = [str(val) for val in row.values]
        row_line = "| " + " | ".join(row_values) + " |\n"
        markdown_content += row_line
    
    markdown_content += "\n\n## Interpretation\n\n"
    markdown_content += "- **Reject H0 (signal)**: Statistically significant disproportionate reporting detected\n"
    markdown_content += "- **Fail to reject H0**: No significant disproportionate reporting detected\n"
    markdown_content += "\n**Flagging Criteria**: PRR ≥ 2.0, χ² ≥ 4.0, N ≥ 3\n"
    
    # Write to file
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(markdown_content)
    
    print(f"✓ Saved Markdown table to: {output_path}")

def print_validation(df, include_topical=False):
    """
    Print validation checks and table preview.
    
    Args:
        df: Final trimmed DataFrame
        include_topical: Whether topical was included
    """
    print("\n" + "="*80)
    print("TRIMMED TABLE VALIDATION")
    print("="*80)
    
    # Print table head
    print("\nTable Preview:")
    print(df.to_string(index=False))
    
    # Validation checks
    print(f"\nValidation Checks:")
    
    # Check MINOXIDIL_SYSTEMIC rows
    systemic_rows = df[df['cohort'] == 'MINOXIDIL_SYSTEMIC']
    print(f"✓ MINOXIDIL_SYSTEMIC rows: {len(systemic_rows)} (expected: 4)")
    assert len(systemic_rows) == 4, f"Expected 4 MINOXIDIL_SYSTEMIC rows, got {len(systemic_rows)}"
    
    # Check total rows if topical included
    if include_topical:
        expected_total = 8  # 4 systemic + 4 topical
        print(f"✓ Total rows with topical: {len(df)} (expected: {expected_total})")
        assert len(df) == expected_total, f"Expected {expected_total} total rows, got {len(df)}"
        
        topical_rows = df[df['cohort'] == 'MINOXIDIL_TOPICAL']
        print(f"✓ MINOXIDIL_TOPICAL rows: {len(topical_rows)} (expected: 4)")
        assert len(topical_rows) == 4, f"Expected 4 MINOXIDIL_TOPICAL rows, got {len(topical_rows)}"
    else:
        expected_total = 4  # 4 systemic only
        print(f"✓ Total rows without topical: {len(df)} (expected: {expected_total})")
        assert len(df) == expected_total, f"Expected {expected_total} total rows, got {len(df)}"
    
    # Check PT order
    unique_pts = df['reaction_pt'].unique()
    print(f"✓ Cardiac endpoints present: {list(unique_pts)}")
    
    # Show flagged signals
    flagged_df = df[df['flagged'] == True]
    if len(flagged_df) > 0:
        print(f"\n🚨 Flagged Signals ({len(flagged_df)}):")
        for _, row in flagged_df.iterrows():
            print(f"   {row['cohort']} + {row['reaction_pt']}: N={row['N']}, PRR={row['PRR']:.1f}")
    else:
        print(f"\n⚪ No flagged signals detected")
    
    print(f"\n✓ All validation checks passed!")

def main():
    """Main CLI entry point."""
    
    parser = argparse.ArgumentParser(
        description="Create trimmed decision tables for MINOXIDIL cardiac endpoints"
    )
    parser.add_argument('--in', dest='input_path', required=True, 
                       help='Input summary CSV file path')
    parser.add_argument('--out', dest='output_path', required=True, 
                       help='Output CSV file path')
    parser.add_argument('--include-topical', action='store_true',
                       help='Include MINOXIDIL_TOPICAL as comparator')
    
    args = parser.parse_args()
    
    print("="*80)
    print("MINOXIDIL CARDIAC ENDPOINTS TRIMMED TABLE GENERATION")
    print("="*80)
    print(f"Input: {args.input_path}")
    print(f"Output: {args.output_path}")
    print(f"Include topical: {args.include_topical}")
    
    try:
        # Load summary data
        df = load_summary_data(args.input_path)
        
        # Filter to target cohorts and endpoints
        filtered_df = filter_to_targets(df, args.include_topical)
        
        # Ensure complete matrix (fill missing combinations)
        complete_df = ensure_complete_matrix(filtered_df, args.include_topical)
        
        # Add decision and interpretation columns
        decision_df = add_decision_columns(complete_df)
        
        # Sort results
        sorted_df = sort_results(decision_df)
        
        # Trim to final columns
        final_df = trim_columns(sorted_df)
        
        # Save CSV
        save_csv(final_df, args.output_path)
        
        # Save Markdown
        markdown_path = args.output_path.replace('.csv', '.md')
        save_markdown(final_df, markdown_path)
        
        # Print validation
        print_validation(final_df, args.include_topical)
        
        print("\n" + "="*80)
        print("TRIMMED TABLE GENERATION COMPLETE")
        print("="*80)
        
    except Exception as e:
        print(f"\n❌ Error: {e}")
        import traceback
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    sys.exit(main())
